version: '3.8'

services:
  # Backend API Service
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    container_name: stock-line-backend
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=production
      - PORT=5000
      - FIREBASE_PROJECT_ID=${FIREBASE_PROJECT_ID}
      - FIREBASE_PRIVATE_KEY_ID=${FIREBASE_PRIVATE_KEY_ID}
      - FIREBASE_PRIVATE_KEY=${FIREBASE_PRIVATE_KEY}
      - FIREBASE_CLIENT_EMAIL=${FIREBASE_CLIENT_EMAIL}
      - FIREBASE_CLIENT_ID=${FIREBASE_CLIENT_ID}
      - FIREBASE_AUTH_URI=${FIREBASE_AUTH_URI}
      - FIREBASE_TOKEN_URI=${FIREBASE_TOKEN_URI}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - WHATSAPP_PHONE_NUMBER=${WHATSAPP_PHONE_NUMBER}
      - OPENWEATHER_API_KEY=${OPENWEATHER_API_KEY}
      - ML_SERVICE_URL=http://ml-service:8000
      - JWT_SECRET=${JWT_SECRET}
    volumes:
      - ./backend/uploads:/app/uploads
    depends_on:
      - ml-service
    restart: unless-stopped
    networks:
      - stock-line-network

  # ML Service (Python FastAPI)
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: stock-line-ml
    ports:
      - "8000:8000"
    environment:
      - OPENWEATHER_API_KEY=${OPENWEATHER_API_KEY}
    volumes:
      - ./ml-service:/app
    restart: unless-stopped
    networks:
      - stock-line-network

  # Frontend (Next.js)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: stock-line-frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:5000/api
      - NEXT_PUBLIC_ML_SERVICE_URL=http://localhost:8000
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - stock-line-network

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: stock-line-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
      - ml-service
    restart: unless-stopped
    networks:
      - stock-line-network

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: stock-line-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    networks:
      - stock-line-network

volumes:
  redis-data:

networks:
  stock-line-network:
    driver: bridge